{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e2dcf84-4742-4074-b6d2-cc6bd35c8fd8",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d8b7455-37dc-4881-ac16-0a5bd58eeb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All necessary libraries have been imported.\n"
     ]
    }
   ],
   "source": [
    "# Import all libraries for the project\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"All necessary libraries have been imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71052b1f-e87b-4ee1-bd3e-50d3920783e6",
   "metadata": {},
   "source": [
    "## Loading Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f394283-e803-47d9-a0e6-bebb72ed8900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ✅ SUCCESS! ---\n",
      "The 20 Newsgroups dataset has been loaded.\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='all', shuffle=True, random_state=42)\n",
    "\n",
    "print(\"--- ✅ SUCCESS! ---\")\n",
    "print(\"The 20 Newsgroups dataset has been loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edac764-4401-4f78-bbcd-5b6ed15be114",
   "metadata": {},
   "source": [
    "## Exploring the Loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22053370-7c80-42ba-ba4f-931d5e13ecbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The categories are:\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "\n",
      "--- Sample Article ---\n",
      "From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
      "Subject: Pens fans reactions\n",
      "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring  the loaded data\n",
    "# The 'target_names' attribute gives us the list of all category names\n",
    "print(\"The categories are:\")\n",
    "print(newsgroups.target_names)\n",
    "\n",
    "# The 'data' attribute is a list of all the articles. Let's look at the first one.\n",
    "print(\"\\n--- Sample Article ---\")\n",
    "print(newsgroups.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897f8845-8016-4559-b362-3ef830dddd41",
   "metadata": {},
   "source": [
    "## Preparing features and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0099dcfe-26e1-4b14-8a29-28db57837d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been prepared and split into training and testing sets.\n"
     ]
    }
   ],
   "source": [
    "# Assign features and target, then split the data\n",
    "# X is the list of articles (our features)\n",
    "X = newsgroups.data\n",
    "# y is the list of categories (our target)\n",
    "y = newsgroups.target\n",
    "\n",
    "# Split our data into a training set and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"Data has been prepared and split into training and testing sets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736abb11-0436-4892-b52e-386d31db45f3",
   "metadata": {},
   "source": [
    "## Building and Training the Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5e1f6ff-5a76-498a-b741-e39944417a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model... (This can take a moment)\n",
      "Model training is complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Create and train the model pipeline\n",
    "# Our model is a pipeline that first vectorizes the text and then applies Naive Bayes\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# We train the model by calling .fit() with our training data\n",
    "print(\"Training the model... (This can take a moment)\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training is complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a01ef9-86f7-4560-8bf7-7f0d03f1574a",
   "metadata": {},
   "source": [
    "## Evaluating the Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e119ff30-745f-4ba0-a5bc-ea8152b4673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ✅ Final Result ---\n",
      "The model's accuracy is: 84.25%\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Make predictions and evaluate the model\n",
    "# Use the trained model to make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Compare the model's predictions to the actual answers to get the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(\"\\n--- ✅ Final Result ---\")\n",
    "print(f\"The model's accuracy is: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d338a-9da5-415d-a8a0-22d979eb2320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
